---
title: CNAPI (Compute Node API) Design
apisections: <%= Object.keys(doc).join(", ") %>
markdown2extras: wiki-tables, code-friendly
---
<!--
    This Source Code Form is subject to the terms of the Mozilla Public
    License, v. 2.0. If a copy of the MPL was not distributed with this
    file, You can obtain one at http://mozilla.org/MPL/2.0/.
-->

<!--
    Copyright (c) 2014, Joyent, Inc.
-->

version: <%= package.version %>
date: <%= (new Date()).toString() %>

# Who

Orlando
Josh

# Overview

CNAPI is the 'Compute Node API' which presents an API to communicate and
interact with Compute Nodes (CNs).

# Responsibilities

CNAPI provides a unified interface to common Compute Node operations, such as
server setup, factory-resetting, virtual machine life-cycle actions (creation,
state transitions, destruction, etc.) In general, if it needs to talk to
compute nodes, it should happen through CNAPI.

# Compute Node Startup

When a compute node is started up from a shutdown state, regardless if it has
been set up, it will broadcast a message containing the payload from the
sysinfo utility. This broadcast message is picked up by CNAPI.


# Interacting with CNAPI

There are two ways of interacting with CNAPI. Indirectly: eg. adminui, cloudapi,
workflow, vmapi. Directly: eg. sdc-cnapi, sdc-server, curl.

Use it as so:

    -bash-4.1# sdc-cnapi /servers/5e4bafa8-9dfd-11e3-982d-a7dee2e79ac4 \
                    -X POST \
                    -d '{ "datacenter_name": "foo" }'


# Heartbeats

Each compute node is populated with services which allow the headnode to
monitor usage and interact with the compute nodes in general. One of these is
the "heartbeater" agent, its responsibility is to periodically emit server and
zone information to AMQP. CNAPI is connects to AMQP and listens for these
heartbeat messages from all servers. It uses the periodic action of these
heartbeats to determine whether a compute node is up.

If a compute node is not setup (and therefore has no agents besides ur), CNAPI
uses the frequency of the sysinfo messages sent by Ur.


# Resetting to Factory Defaults

To reset a compute node to its factory default state, `PUT` to the server's
`factory-reset` endpoint:

    -bash-4.1# sdc-cnapi /servers/564d5f0d-3517-5f60-78f1-ce6d0b8f58df/factory-reset \
                    -X PUT
    HTTP/1.1 202 Accepted
    Content-Type: application/json
    Content-Length: 51
    Date: Tue, 25 Feb 2014 09:24:52 GMT
    Server: Compute Node API
    x-request-id: ae6426e0-9dfe-11e3-96ca-d3493bcec4fe
    x-response-time: 28
    x-server-name: a6b7ba97-deb7-44b1-85da-3d7ae328c710
    Connection: keep-alive

    {
      "job_uuid": "4a664491-aa29-4d77-9fc2-592308d56922"
    }

The UUID of the factory reset job is returned and can be used to poll for the
completion of the operation.


# Virtual Machine Actions

One of the main mechanisms via which CNAPI interacts with compute nodes VMs is via
AMQP messages sent to and received from the provisioner agent on the compute
node.


    -bash-4.1# sdc-cnapi /servers/$(sysinfo |json UUID)/vms/f9940090-a065-11e3-81fd-274008e46b67machine_reboot \
            -X POST \
            -d '{}'

See the reference for the API for available VM endpoitns.



# Remote Execution

CNAPI exposes a mechanism to allow remote execution of commands.

    -bash-4.1# sdc-cnapi /servers/$(sysinfo |json UUID)/execute \
            -X POST \
            -d '{ "script": "#!/bin/bash\necho hi $1 $FOO", "args": ["hello"],
                  "env": { "FOO": "1" } }'

Using the script, args, and env properties we can control the source we
execute, the arguments to that script and any environment variables.


# Boot parameters

When a compute node boots up, its boot-loader fetches the necessary information
from booter. These booter in turn requests this data, consisting of
`boot_platform`, `kernel_flags` and `kernel_modules` from CNAPI.

Operations on boot parameters are done via the `/boot` endpoint.

On the the initial, boot from a "factory default" state, the "default" boot
parameters will be fetched from the `/boot/default` endpoint.

Setting the default boot platform for new compute nodes:

    -bash-4.1# sdc-cnapi /boot/ac586cae-9ace-11e3-a64e-7f4008875a90 \
        -X PUT \
        -d '{ "boot_platform": "20140219T205617Z" }'


Kernel arguments are key/value pairs passed in to the kernel. They are distinct
from kernel flags.

For example, to set the kernel arguments and flags for a compute node with uuid
21306a50-9dad-11e3-9404-53f0c3de6cb8:

    -bash-4.1# sdc-cnapi /boot/21306a50-9dad-11e3-9404-53f0c3de6cb8 \
        -X POST
        -d '{ "kernel_args": { "foo": "bar" }, "kernel_flags": { "-k": true } }'


Passing `null` as the value to a key deletes that key/value.

For instance, to delete the `foo` key:

    sdc-cnapi /boot/21306a50-9dad-11e3-9404-53f0c3de6cb8 \
        -X POST
        -d '{ "kernel_args": { "foo": null } }'


To completely overwrite values, use PUT instead of POST:

    -bash-4.1# sdc-cnapi /boot/21306a50-9dad-11e3-9404-53f0c3de6cb8 \
        -X PUT
        -d '{ "kernel_args": { "alpha": "able" } }'


# Setting up a new Server

Setting when a new server comes online its `status` should be be visible as
'running', and its `setup` state should be `'unsetup'`:

    -bash-4.1# sdc-cnapi /servers | json -Hga uuid setup status
    564d2cec-76f9-2438-7f66-9140267bed05 true running
    564d5f0d-3517-5f60-78f1-ce6d0b8f58df false running


To set up the new server, one may use one of the indirect methods (adminui,
etc).

Additionally, one may also use `sdc-server`:

    -bash-4.1# sdc-server setup 564d5f0d-3517-5f60-78f1-ce6d0b8f58df


Or, sdc-cnapi:

    -bash-4.1# sdc-cnapi /servers/564d5f0d-3517-5f60-78f1-ce6d0b8f58df/setup \
                    -X PUT


# Updating Nics

The only parameter of the server's nics that can be changed is
nic_tags_provided. This parameter can be changed depending on the following
values for the *action* parameter:

* update: Add nic tags to the target nics
* replace: Replace the nic tags (ie: completely overwrite the list) for the
  target nics
* delete: Remove the nic tags from the target nics

## Examples

**update**

Add the manta nic tag to a nic with sdc-cnapi:

    sdc-cnapi /servers/564d4d2c-ddd0-7be7-40ae-bae473a1d53e/nics \
    -X PUT '\
        {
            "action": "update",
            "nics": [
                {
                    "mac": "00:0c:29:a1:d5:3e",
                    "nic_tags_provided": [ "manta" ]
                }
            ]
        }'

Or with sdc-server:

    sdc-server update-nictags -s 564d4d2c-ddd0-7be7-40ae-bae473a1d53e \
        manta_nic=00:0c:29:a1:d5:3e

**replace**

Set the nic tags for a nic to external and mantanat (removing all other nic
tags) with sdc-cnapi:

    sdc-cnapi /servers/564d4d2c-ddd0-7be7-40ae-bae473a1d53e/nics \
    -X PUT '\
        {
            "action": "replace",
            "nics": [
                {
                    "mac": "00:0c:29:a1:d5:3e",
                    "nic_tags_provided": [ "external", "mantanat" ]
                }
            ]
        }'

Or with sdc-server:

    sdc-server replace-nictags -s 564d4d2c-ddd0-7be7-40ae-bae473a1d53e \
        external_nic=00:0c:29:a1:d5:3e mantanat_nic=00:0c:29:a1:d5:3e

**delete**

Remove the mantanat nic tag from a nic with sdc-cnapi:

    sdc-cnapi /servers/564d4d2c-ddd0-7be7-40ae-bae473a1d53e/nics \
    -X PUT '\
        {
            "action": "delete",
            "nics": [
                {
                    "mac": "00:0c:29:a1:d5:3e",
                    "nic_tags_provided": [ "mantanat" ]
                }
            ]
        }'

Or with sdc-server:

    sdc-server delete-nictags -s 564d4d2c-ddd0-7be7-40ae-bae473a1d53e \
        mantanat_nic=00:0c:29:a1:d5:3e

# Server records


A CNAPI server record looks like the following

    -bash-4.1# sdc-cnapi /servers
    HTTP/1.1 200 OK
    Content-Type: application/json
    Content-Length: 9848
    Date: Tue, 22 Apr 2014 08:35:10 GMT
    Server: Compute Node API
    x-request-id: 03f340c0-c9f9-11e3-9a2b-e36882367c85
    x-response-time: 15
    x-server-name: c587f0fc-a962-49cb-a4d2-cd9cb0efb9b9
    Connection: keep-alive
    
    {
      "sysinfo": {
         --- compute node sysinfo ---
      },
      "ram": 4095,
      "current_platform": "20140421T214627Z",
      "headnode": true,
      "boot_platform": "20140421T214627Z",
      "datacenter": "coal",
      "overprovision_ratio": 1,
      "reservation_ratio": 0.15,
      "reservoir": false,
      "traits": {},
      "rack_identifier": "",
      "comments": "",
      "uuid": "564d4374-d703-b97b-ca9f-7375f05f337c",
      "hostname": "headnode",
      "reserved": false,
      "boot_params": {
        "rabbitmq": "guest:guest:rabbitmq.coal.joyent.us:5672"
      },
      "kernel_flags": {},
      "default_console": "vga",
      "serial": "ttyb",
      "setup": true,
      "setting_up": false,
      "last_boot": "2014-04-22T07:39:50.000Z",
      "created": "2014-04-22T07:37:30.000Z",
      "vms": {
         --- compute node vm objects ---
      },
      "transitional_status": "",
      "last_heartbeat": "2014-04-22T08:35:07.776Z",
      "status": "running",
      "memory_available_bytes": 2044813312,
      "memory_arc_bytes": 184096272,
      "memory_total_bytes": 4284993536,
      "memory_provisionable_bytes": -44936986624,
      "disk_kvm_zvol_used_bytes": 0,
      "disk_kvm_zvol_volsize_bytes": 0,
      "disk_kvm_quota_bytes": 0,
      "disk_zone_quota_bytes": 536870912000,
      "disk_cores_quota_bytes": 429496729600,
      "disk_installed_images_used_bytes": 950053376,
      "disk_pool_size_bytes": 159987531776,
      "overprovision_ratios": {
        "ram": 1
      },
      "unreserved_cpu": 400,
      "unreserved_ram": -42863,
      "unreserved_disk": 151669
    }

## Server properties

||**Param**||**Type**||**Description**||
||**boot_params**||*Object*||
||**boot_platform**||*String*||The platform image to be booted from on next boot||
||**current_platform**||*String*||The platform image currently in use by server||
||**comments**||*String*||Description of server||
||**created**||*String date*||Date of server creation||
||**datacenter**||*String*||Datacenter in which server resides||
||**default_console**||||
||**disk_cores_quota_bytes**||||
||**disk_installed_images_used_bytes**||||
||**disk_kvm_quota_bytes**||||
||**disk_kvm_zvol_used_bytes**||||
||**disk_kvm_zvol_volsize_bytes**||||
||**disk_pool_size_bytes**||||
||**disk_zone_quota_bytes**||||
||**headnode**||*Boolean*||Whether server is a headnode||
||**hostname**||*String*||Hostname if any||
||**kernel_flags**||||
||**last_boot**||||
||**last_heartbeat**||||
||**memory_arc_bytes**||||
||**memory_available_bytes**||||
||**memory_provisionable_bytes**||||
||**memory_total_bytes**||||
||**overprovision_ratio**||||
||**overprovision_ratios**||||
||**rack_identifier**||||
||**ram**||*Number*||||
||**reservation_ratio**||||
||**reserved**||*Boolean*||||
||**reservoir**||*Boolean*||||
||**serial**||*String*||||
||**setting_up**||*Boolean*||Whether server is in the process of setting up||
||**setup**||*Boolean*||Whether server has been marked as set up||
||**status**||*Boolean*||The server's current state of activity||
||**sysinfo**||*Object*||The last given sysinfo payload for server||
||**traits**||*Object*||||
||**transitional_status**||*String*||Takes precedense over `status` when a server is undergoing a status change||
||**unreserved_cpu**||||
||**unreserved_disk**||||
||**unreserved_ram**||||
||**uuid**||*String*||The server's unique identifier||
||**vms**||*Object*||A object representing all the vms on server||

# Waitlist

When executing jobs on a server, such vm provision, start, stop, reboot, and
zfs dataset import it is possible that concurrent jobs may interfere with each
other.

To prevent this, a mechanism is required that will queue jobs based on the
type of resource they're acting on. Jobs should be grouped by "scope" and
serialized such that a server can will only execute be executing one job per
scope group at a time. In this way it would be possible to enforce that only
one job be active on a vm on a server, but would still allow jobs to be run
against another vm. Any jobs that come in after one is active will be queued
and dispatch as the previous job finishes.

This system allows for concurrent jobs where the scoping has been set such
that two jobs will not interfere with each other. For instance, two reboot
jobs for two different vms may be run at the same time, however, two reboots
for the same vm will happen in sequential order.

Use of the waitlist is a deliberate process. It is up to the one initiating a job
to create a ticket and wait for it to become active. As such, it is possible
to not use the waitlist at all. However, one then runs the risk of concurrent
jobs trampling each other.

Waitlist tickets are serialized and dispatched one by one according to their
`server_uuid`, `scope` and `id` parameters.

The first step to using the waitlist is to determine the scope and subject (ie
the resource on which the action will be performed). For example this may be
something like 'vm', 'dataset', etc.  This means that the action will be
performed on a resource identified by `id` of the type given by `scope`.

The basic process is as follows: a job starts and it first acquires a ticket
from CNAPI for that particular server and passes in a `scope` and an `id`. 

Because waitlist tickets are serviced in order, once a ticket has been created
the next step is to wait for it to become active. This will happen if there
are no tickets for that scope/id combination, or if waited upon and all
preceding tickets are resolved. To find out whether a ticket has become
'active' (ie indicating the job may proceed and do its work), the job may poll
the ticket values, or use the blocking `wait` endpoint for that ticket.

Once the work has been completed, it is up to the job to "release" the ticket,
so that subsequent tickets for that scope/id combination can be serviced.

Acquiring a ticket before performing work is an explicit step (as opposed to
CNAPI doing the serialization internally) in effort to add transparency and to
know what is happening with the SDC pipeline from just looking at the
top-level workflow for some work to be performed.

### Request (create) a ticket

Using the waitlist begins with requesting a ticket. POST to the
CreateWaitlistTicket endpoint. Specify the scope and unique id. An expiry date
must also be specified. Endpoint returns a ticket uuid.

    -bash-4.1# sdc-cnapi /servers/$(sysinfo | json UUID)/tickets -X POST -d '{ "scope": "vm", "id": "nuts", "expires_at": "2015-10-10T00:00:00"}'
    HTTP/1.1 202 Accepted
    Content-Type: application/json
    Content-Length: 47
    Date: Fri, 27 Jun 2014 19:36:47 GMT
    Server: Compute Node API
    x-request-id: 60c72290-fe32-11e3-913f-b11ed03e831d
    x-response-time: 49
    x-server-name: 9d2c3229-1e92-4c3f-98fd-5a7ac5fb28ed
    Connection: keep-alive

    {
      "uuid": "ec8d5ef3-24b6-4582-ade8-c9e9bfb70906"
    }


### Display all tickets

    -bash-4.1# sdc-cnapi /servers/$(sysinfo | json UUID)/tickets
    HTTP/1.1 200 OK
    Content-Type: application/json
    Content-Length: 260
    Date: Fri, 27 Jun 2014 19:37:12 GMT
    Server: Compute Node API
    x-request-id: 6fcc80a0-fe32-11e3-913f-b11ed03e831d
    x-response-time: 14
    x-server-name: 9d2c3229-1e92-4c3f-98fd-5a7ac5fb28ed
    Connection: keep-alive

    [
      {
        "uuid": "ec8d5ef3-24b6-4582-ade8-c9e9bfb70906",
        "server_uuid": "564d6e71-b375-4b81-07ec-ad77fe5fa680",
        "scope": "vm",
        "id": "nuts",
        "expires_at": "2015-10-10T00:00:00",
        "created_at": "2014-06-27T19:36:47.708Z",
        "updated_at": "2014-06-27T19:36:47.708Z",
        "status": "active"
      }
    ]

### Wait on a ticket

    -bash-4.1# sdc-cnapi /tickets/bb5038c2-7498-4e07-b919-df072c76d2dc/wait
    <returns when ticket is released or expires>


### Release a ticket

    -bash-4.1# sdc-cnapi /tickets/bb5038c2-7498-4e07-b919-df072c76d2dc/release -X PUT
    HTTP/1.1 204 No Content
    Date: Fri, 27 Jun 2014 19:42:46 GMT
    Server: Compute Node API
    x-request-id: 3678cb00-fe33-11e3-913f-b11ed03e831d
    x-response-time: 19
    x-server-name: 9d2c3229-1e92-4c3f-98fd-5a7ac5fb28ed
    Connection: keep-alive


### Delete a ticket

Explicitly deletes a waitlist ticket. This will allow the next ticket in line
for the given scope/id to proceed. The next ticket waiting on the same scope/id
will be allowed to proceed.

    -bash-4.1# sdc-cnapi /tickets/ec8d5ef3-24b6-4582-ade8-c9e9bfb70906 -X DELETE
    HTTP/1.1 204 No Content
    Date: Fri, 27 Jun 2014 19:41:14 GMT
    Server: Compute Node API
    x-request-id: ff8dcd70-fe32-11e3-913f-b11ed03e831d
    x-response-time: 14
    x-server-name: 9d2c3229-1e92-4c3f-98fd-5a7ac5fb28ed
    Connection: keep-alive



# Reference

<% Object.keys(doc).forEach(function (section) { %><% var blocks = doc[section]; %># <%= section %>

<% doc[section].forEach(function (block) { %>## <%= block.name %> (<%= block.endpoint %>)

<%= block.summary %><% if (block.body) { %>

<%= block.body %><% } %>

### Inputs

<% if (block.params.length) { %>||**Param**||**Type**||**Description**||
<% block.params.forEach(function (input) { %>||<%= input.name %>||<%= input.type %>||<%= input.description %>||
<% }); %><% } else { %>_None_
<% } %>

### Responses

<% if (block.responses.length) { %>||*Code*||*Type*||*Description*||
<% block.responses.forEach(function (resp) { %>||<%= resp.code %>||<%= resp.type %>||<%= resp.description %>||
<% }); %><% } else { %>_None_
<% } %>
<% }); %>
<% }); %>
